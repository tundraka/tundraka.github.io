#What's reproducible research about?
- Reproducility and the process it introduces.

#Concepts and ideas
The ultimate standard for strengthening scientific evidence is replication.
Make analytic data/source available, so other people can look at the data, run
the analysis and come to the same results

Studies cannot always be replicated
- No time, opportunistic. The study took 20yrs
- No money
- Unique. situation in time, population.

Why do we need it
- New technologies increase data collection throughput; data are more complex
  and extremely high dimensional.
- Existing databases can be merged into new megadatabases
- Computing power is greatly increased, allowing more sophisticated analyses
- For every field "X" (medicine, astronomy, physics), there's is a field
  "Computational X".

What do we need?
- Analytic data are available
- Analytic code are available
- Documentation of code and data
- Standard means of disribution

Players
- Authors
 - Want their research reproducible
 - need tools for RR
- Readers
 - Want to reproduce
 - Want tools for RR

####Research pipeline

```
Measured Data -> (Processing code) -> Analytic Data -> (Analytic code) ->
Computational Results.

            (Presentation code)
              -> Figures            \
Computational -> Tables              -> Article <- Text
Results       -> Numerical Summaries/
```

#Structure of a Data Analysis
Part 1
- Define the question
- Define the ideal data set
- Determine what data you can access
- Obtain the data
- clean the data

Part 2
- Exploratory data analysis
- Statistical prediction/modeling
- Interpret results
- Challenge results
- Synthetize/Write up results
- Create reproducible code.

####Define the question.
Having a good question is the most effective method to dimension reduction. The more
effort we put into having a reasonable question the less effort that we'll spend
filtering through a lot of stuff. If we can define a question as specifically
as possible that will serve to reduce the knd of noise that you'll have to deal
with when we're going through a potentially big data set.

The science will generally speaking will determine what type of question you're
interesting in asking, this will lead you to the data, which will lead you to
apply statistics.

A proper data analysis has
- a scientific context 
- has at least some general question that we're trying to investigate
- apply the appropriate statistical method to the appropriate data.

*Start with a general question*
Can I automatically detect email that are spam and that are not?

*Make it concrete*
Can I use quatitative characteristics of the emails to classify a SPAM/HAM?

####Define the ideal data set
What's the ideal data set for this problem? The data set may depend on your
goal.
- Descriptive: a whole population
- Exploratory: a random sample with many variables measured
- Inferential: the right population, randomly sampled.
- Predictive: A training and test data set from the same population
- Causal: data from a randomized study
- Mechanistic: data about all components of the system.

####Determine what data you can access
- Find data free on the web
- Buy the data
 - Respect the terms of use
- You may need to generate the data.

####Obtain the data
- Try to obtain the raw data
- Reference the source
- If you need to contact someone to get the data, politness goes a long way.
- getting the data from an internet source, record the URL and the time
  accessed.

####Clean the data
- Raw data often needs to be processed
- If it's pre-processed, make sure you understand how
- Understand the source of the data (census, sample, convenience sample, etc)
- May need to reformat, subsample - (anything that we do, we need to keep track
  of that)
- **Determine if the data are good enough** - if not, quit or change data

####Exploratory data analysis
- Look at the summaries of the data
- Check for missing data
- Create exploratory blobs
- Perform exploratory analyses (e.g. clustering)

####Statistical prediction/modeling
- Should be informed by the results of your exploratory analysis
- Exact methods depend on the question of interest
- Transformations/processing should be accounts for when necessary
- Measures of uncertainty should be reported

####Interpret results
- Use the appropriate language, don't go beyond the analysis we just did.
 - describes
 - correlated with/associated with
 - lead to/causes
 - predicts
- Give an explanation
- Interpret coefficients
- Interpret measures of uncertainty

####Challenge results
- Challenge all steps
 - Question
 - Data source
 - Processing
 - Analysis
 - Conclusions
- Challenge measures of uncertainty
- Challenge choices of terms to include in models
- Think of potential alternatives analyses

####Synthetize/Write up results
- Lead with the question
- Summarize the analyses into the story
- Don't include every analysis, include it
 - if it's needed for the story
 - if it's needed to address a challenge.
- Order analyses according to the story, rather than chronologically
- Include "pretty" figures that contribute to the story.

####Create reproducible code
- Document analysis as we go: knitter
- Make sure that everything we do is reproducible

# Organizing your analysis
There's no universal way to do this, but these are a set of tips to end up with
a good reproduceable research.

- Data
 - Raw data
 - Processed data
- Figures
 - Exploratory figures
 - Final figures
  - Usually a small subsetof the original figures: might be 4-5 figures, take
    a lot of space, many figure may get the message lost.
  - Axes/colors set to make the figure clear
  - Possibly multiple panels
- R code
 - Raw/unused scripts
  - Maybe less commented
  - Multiple versions
  - include analuses and later discarded
 - Final scripts
  - Include processing details
  - Only analyses that appear in the final write-up. Others can be offered but
    not as part of the main one.
 - R markdown files
- Text
 - README files
  - Not necessary if you use R markdown
  - SHould contain step-by-step instruction for analysis
 - Text of analysis / report
  - Include a title, introduction(motivation), methods (statistics you used),
    results (including measures of uncertainty), and conclusions (include
    potential problems)
  - It should tell a story
  - *It should not include every analysis you did*
  - References for statistical method used.

##Further resources
- Project template: a pre-organized set of files for data analysis.
