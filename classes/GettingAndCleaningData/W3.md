#Subsetting and sorting
```R
X[(X$var1 <= 3 & X$var3 >= 10),] # AND
X[(X$var1 <= 3 | X$var3 >= 10),] # OR
X[which($X$var2 > 8),] # which gets an index of rows where the condition is
                       # met, which doesn't include NAs
```

####Sorting
```R
# this only sorts the var1
sort(X$var1, decreasing=T, na.last=T)
# this sorts the row based on var
sort[order(X$var1, X$var2),] #sort first var1, var3

#with plry
library(plyr)
arrange(X, var1)
arrange(X, desc(var1))
```

####Adding rows
```R
X$newVar <- rnorm(5)
Y <- cbind(X, rnorm(5)) # add column
Y <- rbind(Y, rnorm(5)) # add column
```

#Summarizing data
In some sense, this is similar to what we do in exploratory data analysis,
however one thing that I noticed is that if we know something about the data,
for example, there's a column for zip codes, heights, we can make assumptions
like, there wouldn't be any negative number, in the case of zip codes no
decimal numbers, etc. These function can help assert that such assumptions are
true.

####Overview
```R
head(data, n=10) # last 10
tail(data) # last 6
summary(data) # column
str(data)
```

####Quantiles of quantitative data
```R
quantile(data$var, probs=c(0.5, 0.75, 0.9))
```

####Table
```R
# if there's any missing values, a new column will appear. By default table
# doesn't give you the amount of missing values that's why we add the useNa
attribute.
table(data, useNa="ifany")
```

####Check for missing data
```R
sum(is.na(data$column)) # total of missing data in the specified column.
any(is.na(data$column)) # true if there's missing data.
all(data$column > 0) # checks that *all* elements are greated than zero
                     # T when the condition is met.

#combining with colSums
colSums(is.na(data)) # total of na in the different columns
# expect that all sumColums are 0, meaning there are no missing values.
all(colSums(is.na(data)) == 0)
```

####Selecting values with specific characteristics
```R
# select rows that have a zip code in a specified set
table(data[data$zip %in% c('12345', '12346'),])
#or just display the data
data[data$zip %in% c('12345', '12346'),]
```

####Cross tabs
Summaries/cross tabs across several variables.
```R
xt <- xtabs(Freq ~ Gender + Admit, data=DF)
xt <- xtabs(breaks ~ ., data = warpbreaks)
ftable(xt) # easier to see presentation
```

####Size of data set
```R
d <- rnorm(1e5)
object.size(d) # 800040 bytes
print(object.size(d), units='Mb') # 0.8 Mb
```

#Creating new variables
The data set by itself won't provide all the information we need and we may need
to create those, normally by adding columns to the data set we are working
with. Commons variables to create include.

- Missingness indicators
- "Cutting up" quantitative variables
- Applying transforms

####Creating sequences
```R
seq(1, 10, by=2) # 1 3 5 7 9
seq(1, 10, length=3) # 1.0 5.5 10.0
x <- c(1, 3, 6, 8, 4, 5)
seq(along=x) # a sequence with the sequencial indices to access x
             # 1, 2, 3, 4, 5, 6
```

####Creating categorical variables
```R
data$group <- cut(data$var1, breaks=quantile(data$var1))
table(data$group)
table(data$group, dat$var1)

# another way using a library
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g=4)
table(restData$zipGroups)
```

####Creating factors
```R
yesno <- sample(c('yes', 'no'), size=10, replace=T)
# by default the factor 1 is no because of the alphabetic precendec of 'n' over
# 'y'. With this 'yes' is 1.
yesnofac <- factor(yesno, levels=c('yes', 'no'))
relevel(yesnofac, ref='yes')
```

####Other common transforms
- `abs`: absolute value
- `sqrt`: square root
- `ceiling`: round up 3.475 -> 4
- `floor`: round down 3.475 -> 3
- `round(x, digirs=n)`: round using `n` decimals `(3.475, digits=2)` -> 3.48
- `signif(x, digits=n)': `3.475, digits=2` -> 3.5
- `cos`, `sin`, etc.
- `log` natural logarithm
- `log2`, `log10`
- `exp` exponential

####Binary variables
```R
data$less <- ifelse(data$field < 0, T, F) # kinda silly since you can just
                                          # assign the value of the expression
```

#Reshaping data


##Resources
- Andrew Jaffe's R notes: http://www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf
- http://statmethods.net/management/functions.html
- A tutorial from the developer of plyr - http://plyr.had.co.nz/09-user/
- A nice reshape tutorial http://www.slideshare.net/jeffreybreen/reshaping-data-in-r
- A good plyr primer - http://www.r-bloggers.com/a-quick-primer-on-split-apply-combine-problems/
