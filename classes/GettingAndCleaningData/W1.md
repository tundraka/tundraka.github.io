#Obtaining Data - Motivation
*Raw data -> Processing script -> tidy data* -> data analysis -> data
communication
##Raw and processed data
*Data*: Data are values of qualitative or quantitative variables, belonging to
a *set of items*.

- Set of items: sometimes called the population; the set of objects you are
  interested in.
- Variables: A measurement or characteristic of an item.
- Qualitative: Country of origin, sex, treatment
- Quantitative:  Height, weight, blood pressure.

Raw data
- The origin a source of the data
- Often hard to use for data analyses
- Data analysis *includes* processing
- Raw data may only need to be processed once: Keep a record of all the steps
  performed.

Process data (ready for analysis):
- Data ready for analysis
- Processing can include merging, subsetting, transforming, etc.
- There may be standards for processing
- All steps should be recorded.

##Components of tidy data
Four things you should have:
1. The raw data
2. A tidy data set
3. A code book describing each variable and its values in the tidy data set.
   The metadata.
4. An explicit and exact recipe you used to go from 1 to 2, 3

You know the raw data is in the right format if you:
1. Ran no software on the data
2. Did not manipulate any of the numbers in the data
3. You didn't remove any data from the data set
4. You didn't summarize the data in any way.

The tidy data
1. Each variable you easure should be in one column
2. Each different observation of that variable should be in a different row
3. There should be one table for each "kind" of variable
4. If you have multiple tables, they should include a column in the table that
   allows them to be linked.

Other
- name of variables in the top of the file
- Variables should be human readable
- one file per table.

The code book
- Info about variables, units, etc.
- Summary choices, are we using mean, median, etc.
- Information about the experimental study you used.

Other
- Common format, md.
- "Study design" section that describes how the data was collected
- "Code book" section, to describe variables and units.

The instruction list
- Ideally a script in R (or any other script language)
- Input for the script is the raw data
- The output is tidy data
- No params to the script.

If a script if not possible we need to specify what steps will need to be taken
by the user. What software/version/params were used to run, what were the other
steps, etc. The more detail, the better.

##Downloading files
How R can download files? Why with R, downloading can be part of a script.
- `getwd`: get the working directory
- `setwd`: sets the working directory that you may want to move to.
- Changes can be relative or absolute: `setwd('../data')`,
  `setwd('/user/home/data')`

Check that files exists
- `file.exists('directoryName')`: will check if dir exists
- `dir.create('directoryName')`: Created the dir.
```R
if (!file.exists('data')) {
    dir.create('data')
}
```

`download.file()` downloads the file from the internet. Helps with
reproducibility. Important params `url`, `destfile`, `method`. Good for CSV,
text files, etc. If the resource is `https` and we are in a mac, we need to
specify the `method` param to be `curl`.

```R
fileUrl <-'https://yadayada.com/path/file.csv' 
download.file(fileUrl, destfile='./data/somefile.csv', method='curl')
list.files('./data')
```

Files in the internet can change, it's a good practice to track the date when
the file was downloaded, we can do that with:

```R
dateDownload <- date()
```

##Reading local flat files
csv, text, etc.

- `read.table` main function to read data into R.
- Flexible and robust, requires more params
- Reads data into RAM (as other function, AFAIK)
- Important params: `file`, `header`, `sep`, `row.name`, `nrows`
 - `quote`: Whether or not there are quoted values, `quote=''` means no quotes.
 - `na.strings`: the character that represents a missing value.
 - `nrows`: indicated how many rows will be read.
 - `skip`: number of lines to skip before starting to read.
- Related: `read.csv`, `read.csv2`.

Issues with ' or " in the data? Set `quote=""` and that often solves the issue.

##Read excel files
We will use the library `xlsx` to read excel files

```R
library(xlsx)
# sheetIndex <- what sheet to read data from?
data <- read.xlsx('./file.xlsx', sheetIndex=1, header=T)
# if we want to specify rows and columns
colIndex <- 2:3
rowIndex <- 1:4
data <- read.xlsx('./file.xlsx', sheetIndex=1, header=T, colIndex=colIndex,
rowIndex=rowIndex)
```

- `write.xlsx`: writes back an excel file
- `read.xlsx2`: much faster, reading subsets of rows may be slightly unstable.
- The XLConnect package has more options for writing/manipulating excel files
 - The XLConnect vignette good place to start.
- In general, it's easy to distribute data if it's in a CSV, TSV files.

##Reading XML files
```R
library(XML)
fileUrl<-'http://yada.com/file.xml'
data<-xmlTreeParse(fileUrl, useInternal=T)
rootNode<-xmlRoot(data)
xmlName(rootNode)

rootNode[[1]] # first node of root
rootNode[[1]][[1]] # first node of first node of root

# Extracting text
xmlSApply(rootNode, xmlValue) # xmlValue is a function

# Support XPath.
xpathSApply(rootNode, '//name', xmlValue) # extract the text from name nodes

#parsing HTML
fileUrl <- 'http://yada.com/index.html'
html <- htmlTreeParse(fileUrl, useInternal=T)
```

##Reading JSON
```R
library(jsonlite)
jsonData <- fromJSON('http://yada.com/info.json')
names(jsonData)
names(jsonData$owner)
names(jsonData$owner$login)

myjson <- toJSON(iris, pretty=T) # makes it look pretty, optional.
cat(myjson)
#TO data set
data <- from JSON(myjson)
head(data)
```

##Using data.table
A faster more memory efficient version of the data frames.
- Inherits from `data.frame`
- Written in C
- Faster at subsetting, group, and updating.
- Requires a little learning curve.

```R
library(data.table)
df <- data.frame(x=rnorm(9), y=rep(c('a', 'b', 'c'), each=3), z=rnorm(9))
head(df, 3)

dt <- data.table(x=rnorm(9), y=rep(c('a', 'b', 'c'), each=3), z=rnorm(9))
head(dt, 3) # dt listed plus extra info

#see all data tables in memory
tables()

#subsetting rows
dt[2,]
dt[dt$y == 'a',]

#subset rows
dt[c(2, 3)] # do as expected, takes rows 2 and 3
dt[,c(2, 3)] # not what we expect.
```

###Column subsetting in data.table
- The subsetting function is modified for `data.table`
- The argument you pass after the comma is called an *expression*
- In R an expression is a collection of statements enclosed in curly brackets

```R
# example of expressions
{
    x = 1
    y = 2
}

k = {print(10); 5}
```

```R
# x and z are columns in the data table, no quotation marks needed
# we are saying to report the mean of x and sum of z
dt[,list(mean(x), sum(z))]

# get a table of the y column.
dt[,table(y)]

# adding a new calculated column.
# One advantage of this is that with a data frame, when a new column is added,
# R will create a copy of the data frame plus the new column, you end up with 2
# data frames almos identical. With big data sets this can be an issue with memory.
# With data.table this is not the case.
dt[,w:=z^2]
```

In the following example, we see how assigning a data table to a different
variable with the intention of keeping the original doesn't work as expected,
this is similar to assigning by reference where a variable is a pointer to
a common value. We need to copy the variables for this not to happen.

```R
dt2 <- dt # We copy dt into dt2
dt[,y:=2] # We modify dt
head(dt, n=3) # column y is now 2
head(dt2, n=3) # column y is also 2.
```

You can perform multiple step function to create new variables. In the
following example, 
