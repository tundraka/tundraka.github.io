# Hadoop
Apache Hadoop is an open source software framework for storage and large
scale processing of data-sets on clusters of commodity hardware.

- Hadoop moves computation to data.
- Hardware failures handled automatically
- Hadoop mapReduce/HDFS originally derived from Google's mapReduce and FS.
- Keep all data - schema and read style: Read the data and create the schema as
  reading happens.

## Basic modules
- Hadoop common.
 - Libraries and utilities by other Hadoop modules
- Hadoop Distributed File System (HDFS)
 - Distributed file system that stores data in commodity machine, providing
   very high aggregate badnwidth across the entire cluster.
- Hadoop MapReduce
 - Programming model that scales data acorss a lot of different processes.
- Hadoop YARN
 - Resource management platform responsible for managing compute resources
   in the cluster and using them in order to schedule users and apps.

## Hadoop Distributed File System
Distributed, scalable, and portable file system written in Java in order to
support the Hadoop framework.

- Each node in Hadoop instance typically has a single name node.
- And a cluster of data nodes that formed this HDFS cluster
- Each HDFS stores large files, tipicallt in ranges of Gb, Tb
- Reliability is achieved by replicating across multiple hosts

### YARN
Enhances the power of a Hadoop compute cluster, without being limited by the
mapReduce framework.
- Focuses exclusively on scheduling
- 
